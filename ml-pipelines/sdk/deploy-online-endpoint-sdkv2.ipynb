{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient, command, Input, Output, load_component\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Data, Environment, ManagedOnlineEndpoint\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.dsl import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter details of your AML workspace\n",
    "subscription_id = \"\"\n",
    "resource_group = \"\"\n",
    "workspace = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1670200031039
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "# Online Endpoint\n",
    "\n",
    "Online endpoints are endpoints that are used for online (real-time) inferencing. They receive data from clients and can send responses back in real time.\n",
    "\n",
    "An **endpoint** is an HTTPS endpoint that clients can call to receive the inferencing (scoring) output of a trained model. It provides:\n",
    "* Authentication using \"key & token\" based auth\n",
    "* SSL termination\n",
    "* A stable scoring URI (endpoint-name.region.inference.ml.azure.com)\n",
    "\n",
    "A **deployment** is a set of resources required for hosting the model that does the actual inferencing.\n",
    "A single endpoint can contain multiple deployments.\n",
    "\n",
    "Features of the managed online endpoint:\n",
    "\n",
    "* **Test and deploy locally** for faster debugging\n",
    "* Traffic to one deployment can also be **mirrored** (copied) to another deployment.\n",
    "* **Application Insights integration**\n",
    "* Security\n",
    "* Authentication: Key and Azure ML Tokens\n",
    "* Automatic Autoscaling\n",
    "* Visual Studio Code debugging\n",
    "\n",
    "**blue-green deployment**: An approach where a new version of a web service is introduced to production by deploying it to a small subset of users/requests before deploying it fully.\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/endpoint_concept.png\" width = \"500px\" alt=\"Online Endpoint Concept cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "## 1. Create Online Endpoint\n",
    "\n",
    "We can create an **online endpoint** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_online_endpoint.png\" width = \"700px\" alt=\"Create Online Endpoint cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1669584576485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "import random\n",
    "\n",
    "rand = random.randint(0, 10000)\n",
    "\n",
    "endpoint_name = f\"taxi-online-endpoint-{rand}\"\n",
    "# create an online endpoint\n",
    "online_endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name, \n",
    "    description=\"Taxi online endpoint\",\n",
    "    auth_mode=\"aml_token\",\n",
    ")\n",
    "poller = ml_client.____________.begin_create_or_update( ### !!!! TODO !! # Create the online endpoint\n",
    "    online_endpoint,   \n",
    ")\n",
    "\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint creation succeeded\n",
      "auth_mode: aml_token\n",
      "description: Taxi online endpoint\n",
      "id: /subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourceGroups/rg-gasunimlopsv2-prod/providers/Microsoft.MachineLearningServices/workspaces/mlw-gasunimlopsv2-prod/onlineEndpoints/taxi-online-endpoint-4849\n",
      "identity:\n",
      "  principal_id: fedd2b65-e88f-40fb-8b07-3967d185eb35\n",
      "  tenant_id: 1a640b76-52c0-4a5c-b26b-3148406b593f\n",
      "  type: system_assigned\n",
      "kind: Managed\n",
      "location: westeurope\n",
      "mirror_traffic: {}\n",
      "name: taxi-online-endpoint-4849\n",
      "openapi_uri: https://taxi-online-endpoint-4849.westeurope.inference.ml.azure.com/swagger.json\n",
      "properties:\n",
      "  AzureAsyncOperationUri: https://management.azure.com/subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oeidp:9d59d97a-fd9d-4edf-962b-3bc29e6a57e5:2253dc8f-64f9-48ba-a548-fe7af84f266a?api-version=2022-02-01-preview\n",
      "  azureml.onlineendpointid: /subscriptions/5bef918d-59f1-49d6-897b-919e5d5c05a0/resourcegroups/rg-gasunimlopsv2-prod/providers/microsoft.machinelearningservices/workspaces/mlw-gasunimlopsv2-prod/onlineendpoints/taxi-online-endpoint-4849\n",
      "  createdAt: 2025-07-08T13:56:06.039360+0000\n",
      "  createdBy: System Administrator\n",
      "  lastModifiedAt: 2025-07-08T13:56:06.039360+0000\n",
      "provisioning_state: Succeeded\n",
      "public_network_access: enabled\n",
      "scoring_uri: https://taxi-online-endpoint-4849.westeurope.inference.ml.azure.com/score\n",
      "tags: {}\n",
      "traffic: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.exceptions import DeploymentException\n",
    "\n",
    "status = poller.status()\n",
    "if status != \"Succeeded\":\n",
    "    raise DeploymentException(status)\n",
    "else:\n",
    "    print(\"Endpoint creation succeeded\")\n",
    "    endpoint = poller.result()\n",
    "    print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Create Online Deployment\n",
    "\n",
    "To create a deployment to online endpoint, you need to specify the following elements:\n",
    "\n",
    "* Model files (or specify a registered model in your workspace)\n",
    "* Scoring script - code needed to do scoring/inferencing\n",
    "* Environment - a Docker image with Conda dependencies, or a dockerfile\n",
    "* Compute instance & scale settings\n",
    "\n",
    "Note that if you're deploying **MLFlow models**, there's no need to provide **a scoring script** and execution **environment**, as both are autogenerated.\n",
    "\n",
    "We can create an **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/create_online_deployment.png\" width = \"700px\" alt=\"Create Online Deployment cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1669584886619
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instance type Standard_DS2_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
      "Check: endpoint taxi-online-endpoint-4849 exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................."
     ]
    }
   ],
   "source": [
    "# create online deployment\n",
    "from azure.ai.ml.entities import ManagedOnlineDeployment, Model, Environment\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=\"taxi-model@latest\",\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "poller = ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=_____________### !!!! TODO !! # Create the online deployment\n",
    ")\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Allocate Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1670199946158
    }
   },
   "outputs": [],
   "source": [
    "# allocate traffic\n",
    "# blue deployment takes 100 traffic\n",
    "online_endpoint.traffic = {\"blue\": 100}\n",
    "poller = ml_client.begin_create_or_update(online_endpoint)\n",
    "poller.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Invoke and Test Endpoint\n",
    "\n",
    "We can invoke the **online deployment** with cli v2 or sdk v2 using the following syntax:\n",
    "\n",
    "<center>\n",
    "<img src=\"../../imgs/invoke_online_endpoint.png\" width = \"700px\" alt=\"Invoke online endpoint cli vs sdk\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1668246829854
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[11.821297944525352, 15.327631675652293]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke and test endpoint\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    request_file=\"../../data/taxi-request.json\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
